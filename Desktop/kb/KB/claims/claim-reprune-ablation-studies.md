---
type: claim
status: draft
id: claim-reprune-ablation-studies
title: REPrune 消融实验分析
confidence: high
source: Park2024-REPrune
tags:
  - type/claim
  - status/draft
  - confidence/high
  - source/Park2024-REPrune
  - domain/ablation
---

# Intuition

消融实验（Ablation Studies）用于验证 REPrune 各组件的有效性。通过系统地移除或修改某个组件，观察性能变化，从而证明每个设计的必要性。

---

# Rigour

## 1. Linkage 方法对比 (Table 5)

### 实验设置
- **模型**: ResNet-56
- **数据集**: CIFAR-10
- **全局稀疏度**: $\bar{s} = 0.55$

### 结果对比

| Linkage 方法 | FLOPs | Top-1 精度 | 相对 Ward |
|-------------|-------|-----------|----------|
| **Ward** | 基准 | **93.40%** | - |
| Single | 更高 | 较低 | ❌ 更差 |
| Complete | 更高 | 较低 | ❌ 更差 |
| Average | 更高 | 较低 | ❌ 更差 |

### 关键发现

**观察**: 在相同全局稀疏度下，其他 linkage 方法倾向于：
1. **移除前层更多通道** - 前层 FLOPs 更大
2. **信息敏感通道被删除** - 影响精度

**解释**:
- Ward 方法保持簇内紧凑性
- 其他方法可能导致重要通道过早被剪枝
- Ward 的单调性确保稳定的聚类过程

---

## 2. 剪枝 Epoch 数 $T_{prune}$ 的影响 (Table 9)

### 实验设置
- **模型**: ResNet-18
- **数据集**: ImageNet
- **总训练 Epoch**: 250
- **测试范围**: $T_{prune} \in [75, 100, 125, 150, 175, 180, 250]$

### 结果

| $T_{prune}$ | 占总训练比例 | Top-1 精度 | 趋势 |
|------------|-------------|-----------|------|
| 75 | 30% | 较低 | 剪枝过早结束 |
| 100 | 40% | 中等 | 逐步提升 |
| 125 | 50% | 中等 | 继续提升 |
| 150 | 60% | 良好 | 接近最优 |
| 175 | 70% | 良好 | 接近最优 |
| **180** | **72%** | **最优** | ✅ **最佳平衡点** |
| 250 | 100% | 略降 | 可能过剪枝 |

### 结论

> **最佳设置**: $T_{prune} = 180$ (72% 的总训练时间)

**原因分析**:
- $T_{prune}$ 太小 → 剪枝不充分，模型未收敛到最优稀疏结构
- $T_{prune}$ 太大 → 过度剪枝，可能损失重要信息
- 72% 提供了足够的剪枝迭代，同时保留恢复时间

---

## 3. 随机性影响分析 (Table 11)

### 实验设置
- **模型**: ResNet-18
- **数据集**: ImageNet
- **全局稀疏度**: $\bar{s} = 0.6$
- **变量**: 随机种子、候选选择策略

### 结果

| 配置 | FLOPs | Top-1 精度 | 变异 |
|------|-------|-----------|------|
| Seed 1 | 基准 | 基准 | - |
| Seed 2 | ±变化 | ±变化 | 小幅度 |
| Seed 3 | ±变化 | ±变化 | 小幅度 |
| 替代选择策略 1 | ±变化 | ±变化 | 中等 |
| 替代选择策略 2 | ±变化 | ±变化 | 中等 |

### 关键发现

**观察**: 
- 不同随机种子导致结果有小幅波动
- 但总体趋势保持一致
- 随机性有助于探索不同的剪枝路径

**启示**:
- 随机采样在候选滤波器分数相同时是合理的
- 更好的选择策略可能进一步提升性能
- 当前策略已达到较好的稳定性

---

## 4. 训练范式对比 (Table 10)

### 对比设置
- **方法 1**: REPrune (单阶段并发训练-剪枝)
- **方法 2**: REPrune-adapted (改为 train-prune-finetune 三阶段)
- **模型**: ResNet-56
- **数据集**: CIFAR-10
- **全局稀疏度**: $\bar{s} = 0.55$

### 结果对比

| 指标 | REPrune (单阶段) | 三阶段改编 | 优势 |
|------|------------------|-----------|------|
| FLOPs 减少 | **60.38%** | 56.96% | +3.42% |
| Top-1 精度 | **93.40%** | 93.02% | +0.38% |
| 训练时间 | **160 epochs** | 320 epochs | **50%↓** |

### 核心优势

1. **更高的 FLOPs 减少率**
   - 并发优化使剪枝更充分
   - 渐进式剪枝避免一次性过度剪枝

2. **更好的精度保持**
   - 联合优化使模型适应剪枝结构
   - 避免 finetune 时的性能损失

3. **显著的时间节省**
   - 减少 50% 的训练时间
   - 无需额外的 finetune 阶段

---

## 5. Coverage Rate 分析 (Fig. 3)

### 概念

**Coverage Rate** = 已覆盖簇数 / 总簇数

反映所选滤波器对核模式的代表程度。

### 观察趋势

| 训练阶段 | Coverage Rate | 说明 |
|---------|--------------|------|
| 早期 | 较低 | 后层簇占主导 |
| 中期 | 中等 | 前层稀疏度增加 |
| 后期 | **高 (>90%)** | 贪心算法优化充分 |

### 关键发现

- **渐进优化**: Coverage rate 随训练稳步提升
- **贪心有效性**: MCP 贪心算法能有效最大化覆盖
- **稳定性**: 后期 coverage rate 趋于稳定，说明收敛

---

# Evidence

| 来源 | 内容 |
|------|------|
| Table 5 p7 | Linkage 方法对比 |
| Table 9 Appendix | $T_{prune}$ 影响 |
| Table 10 Appendix | 训练范式对比 |
| Table 11 Appendix | 随机性分析 |
| Fig. 3 p7 | Coverage rate 变化 |

---

# Links

- **支持**: [[concepts/concept-reprune|REPrune]] (置信度: high)
- **相关**: [[methods/method-kernel-clustering-ward|Ward Linkage]] (置信度: high)
- **相关**: [[methods/method-reprune-algorithm2|Algorithm 2]] (置信度: high)
- **相关**: [[claims/claim-reprune-experiments-detailed|详细实验结果]] (置信度: high)
